{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n",
    "\n",
    "module_path = os.path.abspath(\"/seq/vgb/bryc/projects/pheno\")\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import pheno\n",
    "from pheno import PhenoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = {\n",
    "    '2018-12-08': np.nan,\n",
    "    '2016-10-30': np.nan,\n",
    "    '2017-03-03': np.nan,\n",
    "    '8-10': \"9\",\n",
    "    'born about 2011' : np.nan,\n",
    "    '9 years': \"9\",\n",
    "    '2017-02-16' : np.nan,\n",
    "    '3 1/2': \"3.5\",\n",
    "    '2017-06-24' : np.nan,\n",
    "    '1 year': \"1\",\n",
    "    '12-13 years old': \"12.5\", \n",
    "    '2ish': \"2\", \n",
    "    '2 1/2': \"2.5\",\n",
    "    '1-2 yrs': \"1.5\",\n",
    "    '8 years': \"8\",\n",
    "    '4-5 years': \"4.5\",\n",
    "    '2017-11-26' : np.nan,\n",
    "    '2009-09-01' : np.nan, \n",
    "    '2016-01-01' : np.nan,\n",
    "    '2011-05-29' : np.nan,\n",
    "    '2012-01-05' : np.nan,\n",
    "    '2013-03-01' : np.nan,\n",
    "    '3.5 yrs': \"3.5\",\n",
    "    '5 months': \"0.42\",\n",
    "    'about 9': \"9\", \n",
    "    '5 ?': \"5\",\n",
    "    '12 weeks':\"0.25\" ,\n",
    "    '5-6': \"5.5\", \n",
    "    '3 years': \"3\", \n",
    "    '4;&#39;': \"4\",\n",
    "    '10months': \"0.83\", \n",
    "    '7-10': \"8\",\n",
    "    '011 months': \"0.92\",\n",
    "    '23 months': \"1.92\",\n",
    "    '123 months': np.nan,\n",
    "    '1 yr, 4 mos':\"1.33\", \n",
    "    '5m': \"0.42\", \n",
    "    '9 months' : \"0.75\",\n",
    "    '6th': np.nan, \n",
    "    '6 months': \"0.5\",\n",
    "    '1year':\"1.0\",\n",
    "       '1.5 yr': \"1.5\",\n",
    "    '11?': \"11\",\n",
    "    '10 mos': \"0.83\",\n",
    "    '11 months': \"0.92\",\n",
    "    'about 15': \"15\", \n",
    "    '19 weeks': \"0.4\" ,\n",
    "    '20 months': \"1.67\",\n",
    "    '3ish': \"3\", \n",
    "    '08': np.nan,\n",
    "    '13ish': \"13\",\n",
    "    '3.5 months':\"0.29\",\n",
    "    '5 mo': \"0.42\",\n",
    "    '3 yr': \"3\",\n",
    "    '~10 mo.':\"0.83\",\n",
    "    '15?': \"15\",\n",
    "    '3 +/-': \"3\",\n",
    "    '10 months': \"0.83\",\n",
    "    'About 7 years, 10 months': \"7.83\",\n",
    "    '9+ years': \"9\",\n",
    "    '~5': \"5\",\n",
    "    '12 months': \"1.0\",\n",
    "    'approx 7 years': \"7\",\n",
    "    '9 mos': \"0.75\",\n",
    "    '16mo': \"1.33\",\n",
    "    '06 months': \"0.5\",\n",
    "    '7mos.': \"0.58\",\n",
    "    '9mo': \"0.75\",\n",
    "    '2-ish': \"2\", '55':np.nan,\n",
    "    '16 months': \"1.33\",\n",
    "    '20 mos': \"1.67\", \n",
    "    '?':np.nan,\n",
    "    '07 months':\"0.58\",\n",
    "    '66':np.nan, \n",
    "    '10-12': \"11\",\n",
    "    '6 mo': \"0.5\",\n",
    "    '6 + / -':\"6\",\n",
    "    'NOT SURE 300 YEARS REINCARNATED':np.nan,\n",
    "    '6+9mos': \"6.82\",\n",
    "    '77': np.nan,\n",
    "    '15ish': \"15\",\n",
    "    '8?': \"8\",\n",
    "    '8 months': \"0.67\",\n",
    "    '03': \"0.3\",\n",
    "    '33': np.nan,\n",
    "    '22': np.nan, \n",
    "    '1y7mos': \"1.58\",\n",
    "    '9-10 yo': \"9.5\",\n",
    "    '10?': \"10\",\n",
    "    '7 weeks': \"0.15\",\n",
    "    '1 1/2': \"1.5\",\n",
    "    '5 1/2': \"5.5\",\n",
    "    '4y/5m': \"4.42\",\n",
    "    '8mo': \"0.67\",\n",
    "    '9 weeks': \"0.19\",\n",
    "    '01': np.nan,\n",
    "    '9mos': \"0.75\",\n",
    "    '6mo': \"0.5\",\n",
    "    '07': \"7\",\n",
    "    '6 YO': \"6\",\n",
    "    '5 mos': \"0.42\",\n",
    "    '2014': np.nan,\n",
    "    '7 1/2 yrs old': \"7.5\",\n",
    "    \"5 or 6 years\": \"5.5\",\n",
    "    \"2 1/2 years\": \"2.5\",\n",
    "    \"5 to 7 years old\": \"6.0\",\n",
    "    \"6 or 7 years\": \"6.5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/seq/vgb/bryc/data/darwins_dogs/2024-09-23_cache\"\n",
    "ph = PhenoDB(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5adbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the SRA uploaded dog IDs and subset to those\n",
    "SRA_file = \"/seq/vgb/rawData/gencove/DarwinsArk/fastq/SRA/sampleIDs.txt\"\n",
    "filenames = pd.read_csv(SRA_file, header=None)\n",
    "filenames[['DA', 'dogID', 'barcode']] = filenames[0].str.split('_', n=2, expand=True)\n",
    "filenames['dogID'] = filenames.dogID.astype(int)\n",
    "# Fix two incorrect SRA file dogIDs (filenames were incorrect, dog is correct in spreadsheet/data):\n",
    "filenames[\"dogID\"] = filenames[\"dogID\"].replace({26971: 26961, 12450:12350})\n",
    "SRA_2024 = pd.read_csv(\"/seq/vgb/rawData/gencove/DarwinsArk/fastq/2024-08-22_SRA/files/2024-08-22_SRA.csv\")\n",
    "all_SRA_dogs = (SRA_2024['darwinsark_id'].tolist() + filenames['dogID'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e044a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_SRA_dogs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78912e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup of sex, neuter, purebred, and age\n",
    "subset = ph.dogs[ph.dogs.id.isin(all_SRA_dogs)].copy()\n",
    "subset[\"sex\"] = subset['sex'].replace({\"Male\": \"male\", \"Female\": \"female\"})\n",
    "subset[\"neutered\"] = subset['neutered'].replace({\"Yes\": \"yes\", \"No\": \"no\"})\n",
    "subset[\"purebred\"] = subset[\"purebred\"].replace({\"1\": \"yes\", \"0\": \"no\", \"-1\": np.NaN})\n",
    "subset[\"age\"] = subset[\"age\"].replace(age_map)\n",
    "# Remove non-plausible ages\n",
    "subset.loc[subset.age_norm > 25, \"age_norm\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353b344",
   "metadata": {},
   "source": [
    "### Get `age_composed` which will combine the best information across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782e5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset['creation_date']= pd.to_datetime(subset['creation_date'])\n",
    "subset['birthday']= pd.to_datetime(subset['birthday'])\n",
    "subset[\"deceased_date\"] = pd.to_datetime(subset['deceased'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e562e80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subset[\"inferred_age\"] = (subset['creation_date'] - subset['birthday']) / timedelta(days=365)\n",
    "subset[\"numeric_age\"] = pd.to_numeric(subset[\"age\"], errors='coerce')\n",
    "subset[\"age_at_death\"] = (subset['deceased_date'] - subset['birthday']) / timedelta(days=365)\n",
    "subset[\"age_composed\"] = subset[\"age_norm\"].fillna(subset[\"inferred_age\"])\n",
    "subset[\"age_composed\"] = subset[\"age_composed\"].fillna(subset[\"numeric_age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cols = [\"id\", \"age\", \"creation_date\", \"birthday\", \"age_composed\", \"age_norm\", \"birthday_historical\", \"inferred_age\", \"numeric_age\", \"age_at_death\"]\n",
    "subset[subset.age_norm - subset.inferred_age > 0.5][age_cols]\n",
    "\n",
    "# Overwrite with the manually entered age because there is a typo in the birthyear\n",
    "subset.loc[subset.id == 2144, \"age_composed\"] = 4.0\n",
    "subset.loc[subset.id == 11503, \"age_composed\"] = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc99df",
   "metadata": {},
   "source": [
    "### Get breed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4dfdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_breed = dict(zip(ph.breeds.id, ph.breeds.breed_print))\n",
    "for column in ['breed1_id','breed2_id', 'breed3_id']:\n",
    "    subset[column] = subset[column].replace(id_to_breed)\n",
    "subset[['breed1_id','breed2_id', 'breed3_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930c5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined breed information between older freetext data and recent ID columns\n",
    "subset['breed1'] = subset['breed1'].fillna(subset['breed1_id'])\n",
    "subset['breed2'] = subset['breed2'].fillna(subset['breed2_id'])\n",
    "subset['breed3'] = subset['breed3'].fillna(subset['breed3_id'])\n",
    "\n",
    "# Clean up messy manually-entered breed names\n",
    "manual_fixes = {\"beagle \\\"plus\\\" ... tri-color white + liver + brown; brown \\\"freckles\\\" on white legs\": \"Beagle\",\n",
    "               \"sato\": \"Sato\",\n",
    "               \"miniature australian shepherd\": \"Miniature Australian Shepherd\",\n",
    "               \"Black mouth curr\": \"Black Mouth Cur\",\n",
    "               \"wire haired fox terrier\": \"Wire Fox Terrier\",\n",
    "               \"Wire Haired Fox Terrier\": \"Wire Fox Terrier\",\n",
    "               \"Congo dog\": \"Basenji\",\n",
    "               \"Swiss White Shepherd\":\"White Swiss Shepherd Dog\",\n",
    "               \"Hamiltonstovare\": \"Hamilton Hound\",\n",
    "               \"labradoodle\": \"Labradoodle\",\n",
    "               \"50% Chihuahua \":\"Chihuahua\",\n",
    "               \"50% Australian Kelpie \": \"Australian Kelpie\",\n",
    "               \"Akbash Dog\": \"Akbash\",\n",
    "               \"Berger Blanc Suisse\": \"White Swiss Shepherd Dog\",\n",
    "               'German Munsterhund': \"Small Münsterländer\",\n",
    "               \"Xoloitzcuintli\": \"Mexican hairless dog\",\n",
    "               \"Black & Tan Coonhound\": \"Black and Tan Coonhound\",\n",
    "               \"Louisiana Catahoula Leopard Dog\": \"Catahoula Leopard Dog\",\n",
    "               \"German Shepherd Dog (50%)\": 'German Shepherd Dog',\n",
    "               \"windsprite\": \"Silken Windsprite\",\n",
    "               \"Golden Retriever?\": \"Golden Retriever\",\n",
    "               \"miniature dachshund\": \"Miniature Dachshund\",\n",
    "               \"American Black and Tan Coonhound\": \"Black and Tan Coonhound\",\n",
    "               \"Plott\": \"Plott Hound\",\n",
    "               \"Red Heeler\": \"Australian Cattle Dog\",\n",
    "               \"Flat-coated Retrievers\": \"Flat-Coated Retrievers\",\n",
    "               \"Blue Heeler\": \"Australian Cattle Dog\",\n",
    "               \"mixed\":np.nan,\n",
    "                \"Mix\": np.nan,\n",
    "               \"tennesee brindle mountain cur\": \"Treeing Tennessee Brindle\",\n",
    "               \"Chihuahua (Long\": \"Chihuahua (Long Coat)\",\n",
    "               \" Boarder Collie \": \"Border Collie\",\n",
    "               \"25% GSD\": \"German Shepherd\",\n",
    "               \"25% Chow\": \"Chow Chow\",\n",
    "               \"larger hound\": np.nan,\n",
    "                \"australian kelpie\": \"Australian Kelpie\",\n",
    "               \"catahoula leopard dog\": \"Catahoula Leopard Dog\"}\n",
    "subset[\"breed1\"]= subset.breed1.replace(manual_fixes)\n",
    "subset[\"breed2\"]= subset.breed2.replace(manual_fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44566d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use breed2 results if breed1 is missing\n",
    "subset['breed1'] = subset['breed1'].fillna(subset['breed2'])\n",
    "subset.loc[subset.breed1 == subset.breed2,'breed2'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc0f88",
   "metadata": {},
   "source": [
    "### Get ancestry results for all dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry = pd.read_csv(os.path.join(cache_dir, \"dog_breed.csv\"))\n",
    "ancestry = ancestry[ancestry.version == \"v2\"]\n",
    "ancestry[\"breed\"] = ancestry[\"breed\"].replace(id_to_breed)\n",
    "samples  = pd.read_csv(os.path.join(cache_dir, \"samples.csv\"))\n",
    "non_na_samples = samples[~samples.dog.isna()]\n",
    "barcode_to_dog = dict(zip(non_na_samples.barcode, non_na_samples.dog))\n",
    "dog_to_barcode = {v: k for k, v in barcode_to_dog.items()}\n",
    "ancestry[\"id\"] = ancestry[\"barcode\"].map(barcode_to_dog)\n",
    "with_ancestry = ancestry.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd88301",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = [dog  for dog in subset.id if dog not in with_ancestry]\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90b81cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_fixes = {}\n",
    "barcodes_with_anc_results = ancestry.barcode.unique()\n",
    "\n",
    "for dog in missing:\n",
    "    try:\n",
    "        barcode = dog_to_barcode[dog]\n",
    "        if (barcode + \"-a\") in barcodes_with_anc_results:\n",
    "            barcode_fixes[barcode + \"-a\"] = dog\n",
    "        else:\n",
    "            print(\"No results for barcode\", barcode, \"and dog\", dog)\n",
    "    except:\n",
    "        print(\"dog \", dog, \" not found in samples table\")\n",
    "\n",
    "ancestry[\"id\"] = ancestry[\"id\"].fillna(ancestry[\"barcode\"].map(barcode_fixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side bar: let's make a file to address these 128 mismapped dogs and give them breed results\n",
    "import time\n",
    "\n",
    "unix_timestamp = int(time.time()) \n",
    "mismapped_barcode_file = \"/seq/vgb/rawData/gencove/raw/doc/2024-09-30_Kasia_mismapped_barcode_fixes.txt\"\n",
    "with open(mismapped_barcode_file, \"w\") as file1:\n",
    "    for barcode, dog in barcode_fixes.items():\n",
    "        # Writing data to a file\n",
    "        file1.write(f\"insert into samples (time,type,barcode,dog,location1,project) values ({unix_timestamp},1,\\\"{barcode}\\\",{dog},17,1);\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_ancestry = ancestry.id.unique()\n",
    "still_missing = [dog  for dog in subset.id if dog not in with_ancestry]\n",
    "\n",
    "print(len(still_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d6f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_fix = {}\n",
    "for dog in filenames[filenames.dogID.isin(still_missing)].dogID.values:\n",
    "    try:\n",
    "        bar = dog_to_barcode[dog]\n",
    "        to_fix[dog] = bar\n",
    "    except:\n",
    "        print(\"no barcode for dog \", dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd216eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup = ancestry.drop_duplicates(keep='last', subset = [\"id\", \"breed\"])\n",
    "df = dedup.pivot(index='id', columns='breed', values='percent').reset_index()\n",
    "ancestries = df[df.id.isin(subset.id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de8d90",
   "metadata": {},
   "source": [
    "### Prepare merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc858d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = ['id',\n",
    " 'name',\n",
    " 'sex',\n",
    " 'neutered',\n",
    " 'creation_date',\n",
    " 'age_composed',\n",
    " 'age',\n",
    " 'age_norm',\n",
    " 'numeric_age',\n",
    " 'inferred_age',\n",
    " 'dob_known',\n",
    " 'birthday',\n",
    " 'birthday_historical',\n",
    " 'breed1',\n",
    " 'breed2',\n",
    " 'breed3',\n",
    " 'purebred',\n",
    " 'deceased_date',\n",
    " 'age_at_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588fb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[useful_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d81487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge phenotypes with ancestries\n",
    "ancestries = ancestries.fillna(0)\n",
    "phenotypes = pd.merge(subset[useful_cols], ancestries, how = \"outer\", on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3095ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed = \"Boxer\"\n",
    "phenotypes[phenotypes.breed1 == breed][breed].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26193dad",
   "metadata": {},
   "source": [
    "## Compute behavior factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_loadings=pd.read_csv(\"/seq/vgb/bryc/projects/dog_behavioral_gwas_paper/data/DarwinsArk_20221120_factor-analysis_discovery-no-na_qn-182_dn-7883_fn-25.loadings.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bec4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = ph.df.reset_index().rename(columns={\"dog\": \"id\"})\n",
    "answers = answers[answers.id.isin(all_SRA_dogs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda4ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the input data for a range of 0 to 6\n",
    "all_qs= factor_loadings.question.unique()\n",
    "columns = [\"id\"] + list(all_qs)\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 6))\n",
    "scaled = scaler.fit_transform(answers[all_qs])\n",
    "scaled_features_df = pd.DataFrame(scaled, index=answers.index, columns=all_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27148885",
   "metadata": {},
   "outputs": [],
   "source": [
    "for factor in factor_loadings.factor.unique():\n",
    "    loadings = factor_loadings[factor_loadings.factor == factor][['question', 'pattern']].set_index('question')\n",
    "    df = scaled_features_df[loadings.index]\n",
    "    answers[\"factor_\" + str(factor)] = df.dot(loadings.pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da1911",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a5108",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.factor_16.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phenotypes = pd.merge(phenotypes, answers, on=\"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c3c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phenotypes.to_csv(\"/seq/vgb/bryc/data/darwins_dogs/2024-09-23_cache/merged_phenotype_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85235a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
